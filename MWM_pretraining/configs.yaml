defaults:

  # Train Script
  logdir: ./finetuning_result/debug
  load_logdir: /home/hchen/processed_somethingv2/
  seed: 0
  task: dmc_walker_walk
  render_size: [64, 64]
  dmc_camera: -1
  camera: none
  atari_grayscale: True
  time_limit: 0
  action_repeat: 1
  steps: 1e8
  log_every: 1e4
  eval_every: 5000
  pretrain: 1
  train_every: 5
  train_steps: 1
  replay: {capacity: 2e6, minlen: 50, maxlen: 50, prioritize_ends: True}
  dataset: {batch: 16, length: 50}
  mae_dataset: {batch: 32, length: 32}
  log_keys_video: ['image']
  log_keys_sum: '^$'
  log_keys_mean: '^$'
  log_keys_max: '^$'
  precision: 16
  jit: True

  # Agent
  clip_rewards: identity

  # MAE
  mask_ratio: 0.75
  mae: {img_size: 64, patch_size: 8, embed_dim: 256, depth: 4, num_heads: 4, decoder_embed_dim: 256, decoder_depth: 3, decoder_num_heads: 4, reward_pred: False, early_conv: True, in_chans: 3}
  wm_flat_vit: {img_size: 8, patch_size: 1, embed_dim: 1024, depth: 2, num_heads: 8, decoder_embed_dim: 1024, decoder_depth: 2, decoder_num_heads: 8, in_chans: 256, stoch: 32, discrete: 32}


  # World Model
  grad_heads: [decoder]
  tssm: {action_free: True, hidden: 1024, deter: 1024, stoch: 32, discrete: 32, act: elu, norm: none, std_act: sigmoid2, min_std: 0.1, deter_type: concat_o, n_trans_layers: 6, n_head: 8, d_inner: 64, dropout: 0.1, dropatt: 0.1, pre_lnorm: True, d_ff_inner: 1024}
  loss_scales: { feature: 1.0, kl: 1.0, reward: 1.0, discount: 1.0, proprio: 1.0, mae_reward: 1.0 }
  wmkl: { scale: 1.0 }
  wmkl_minloss: 0.0
  wmkl_balance: 0.8
  model_opt: { opt: adam, lr: 3e-4, eps: 1e-5, clip: 100.0, wd: 1e-6, wd_pattern: 'kernel', warmup: 0 }
  mae_opt: { opt: adam, lr: 3e-4, eps: 1e-5, clip: 100.0, wd: 1e-6, warmup: 0 }

atari_pretrain:

  task: atari_pong
  encoder: {mlp_keys: '$^', cnn_keys: 'image'}
  decoder: {mlp_keys: '$^', cnn_keys: 'image'}
  time_limit: 27000
  action_repeat: 4
  steps: 5e7
  log_every: 500
  train_every: 5
  clip_rewards: tanh
  rssm: {hidden: 600, deter: 600}
  grad_heads: [decoder]
  model_opt.lr: 2e-4
  loss_scales.kl: 0.1

metaworld_pretrain:

  task: metaworld_door_open
#  encoder: {mlp_keys: '$^', cnn_keys: 'image'}
#  decoder: {mlp_keys: '$^', cnn_keys: 'image'}
  replay: {minlen: 25, maxlen: 25}
  dataset: {batch: 16, length: 25}
  action_repeat: 1
  steps: 5e7
  log_every: 100
  train_every: 1
  grad_heads: [decoder]
  model_opt.lr: 3e-4
  loss_scales.kl: 0.1

dmc_vision_pretrain:
  task: dmc_walker_walk
  encoder: {mlp_keys: '$^', cnn_keys: 'image'}
  decoder: {mlp_keys: '$^', cnn_keys: 'image'}
  action_repeat: 2
  log_every: 500
  pretrain: 100
  clip_rewards: identity
  replay.prioritize_ends: False
  grad_heads: [decoder]
  rssm: {hidden: 200, deter: 200}
  model_opt.lr: 3e-4
  kl.free: 1.0

somethingv2:
  task: dmc_walker_walk
  replay: {minlen: 50, maxlen: 50}
  dataset: {batch: 16, length: 50}
  mae_dataset: {batch: 32, length: 32}
  action_repeat: 1
  steps: 5e7
  log_every: 100
  train_every: 1
  grad_heads: [decoder]
  model_opt.lr: 3e-4
  loss_scales.kl: 0.1